{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4472a90d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import pandas as pd\n",
    "import os\n",
    "import librosa as libr\n",
    "import gc\n",
    "import IPython.display as ipd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import scipy.signal as signal\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cf022a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate Mel Frequency Cepstral Coefficient\n",
    "def generate_fb_and_mfcc(signal, sample_rate):\n",
    "    # ... (existing code for generating filter banks)\n",
    "    return filter_banks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1302fa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Sourcing\n",
    "hindi = '/kaggle/input/audio-dataset-with-10-indian-languages/Language Detection Dataset/Hindi/'\n",
    "bengali = '/kaggle/input/audio-dataset-with-10-indian-languages/Language Detection Dataset/Bengali/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e313467f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Validation and Cleaning\n",
    "def validate_and_clean_data(file_path, language):\n",
    "    try:\n",
    "        data, samplerate = libr.load(file_path)\n",
    "        # Additional validation and cleaning steps if needed\n",
    "        # ...\n",
    "\n",
    "        return data, samplerate\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file: {file_path}, Error: {str(e)}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039a4936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Labeling\n",
    "def label_data(file_name, language):\n",
    "    # Implement labeling based on the file name or any other relevant information\n",
    "    # ...\n",
    "\n",
    "# Data Sourcing, Validation, Cleaning, and Labeling\n",
    "def process_data(language_path, train_size, lang_label):\n",
    "    data_list = []\n",
    "    label_list = []\n",
    "    \n",
    "    for filename in os.listdir(language_path)[:train_size]:\n",
    "        file_path = os.path.join(language_path, filename)\n",
    "        data, samplerate = validate_and_clean_data(file_path, lang_label)\n",
    "        \n",
    "        if data is not None:\n",
    "            data_list.append(data)\n",
    "            label_list.append(label_data(filename, lang_label))\n",
    "\n",
    "    return data_list, label_list\n",
    "\n",
    "# Define train_size0 and train_size1\n",
    "train_size0 = 5000\n",
    "train_size1 = int(train_size0 * 0.2)\n",
    "\n",
    "# Initialize lists for data and labels\n",
    "data_all = []\n",
    "labels_all = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17624804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process each language\n",
    "languages = [hindi, marathi, tamil, telugu, bengali, gujarati, kannada, malayalam, punjabi, urdu]\n",
    "for language_path, lang_label in zip(languages, ['hindi', 'marathi', 'tamil', 'telugu', 'bengali', 'gujarati', 'kannada', 'malayalam', 'punjabi', 'urdu']):\n",
    "    data_lang, labels_lang = process_data(language_path, train_size0 if lang_label == 'hindi' else train_size1, lang_label)\n",
    "    data_all.extend(data_lang)\n",
    "    labels_all.extend(labels_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab3266a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataFrame for the labeled data\n",
    "data_dict = {'Data': data_all, 'Label': labels_all}\n",
    "df_labeled = pd.DataFrame(data_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70269c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into Train and Test sets\n",
    "train_df, test_df = train_test_split(df_labeled, stratify=df_labeled['Label'], test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23736e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the labeled data\n",
    "print(train_df['Label'].value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
